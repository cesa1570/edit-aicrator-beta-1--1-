import { GoogleGenAI, Type, Modality } from "@google/genai";
import { ScriptData, GeneratorMode, NewsItem, SocialPostData, PolishStyle, Scene } from "../types";

export const ERR_INVALID_KEY = "API_KEY_INVALID";

export const notifyApiUsage = () => {
  window.dispatchEvent(new CustomEvent('gemini-api-usage'));
};

const getClient = () => {
  // Priority: 1. User's API Key from localStorage, 2. Environment variable
  const userApiKey = typeof window !== 'undefined' ? localStorage.getItem('gemini_api_key') : null;
  console.log("Debug: API Key Check", {
    localStorage: userApiKey ? "FOUND" : "MISSING",
    viteEnv: import.meta.env.VITE_GEMINI_API_KEY ? "FOUND" : "MISSING",
    processEnv: (process.env as any).API_KEY ? "FOUND" : "MISSING"
  });
  const apiKey = userApiKey || import.meta.env.VITE_GEMINI_API_KEY || (process.env as any).API_KEY;
  if (!apiKey) throw new Error("API Key not found. Please add your Gemini API Key in Settings.");
  return new GoogleGenAI({ apiKey });
};

const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

const detectLanguage = (text: string): 'Thai' | 'English' => {
  return /[‡∏Å-‡πô]/.test(text) ? 'Thai' : 'English';
};

const withRetry = async <T>(operation: () => Promise<T>, retries = 3, initialDelay = 3000): Promise<T> => {
  let lastError: any;
  for (let i = 0; i < retries; i++) {
    try {
      const result = await operation();
      notifyApiUsage();
      return result;
    } catch (error: any) {
      lastError = error;
      const msg = (error.message || "").toLowerCase();
      if (msg.includes('requested entity was not found')) {
        const keyErr = new Error("Invalid Key or Project.");
        (keyErr as any).code = ERR_INVALID_KEY;
        throw keyErr;
      }
      if (msg.includes('429') || msg.includes('quota') || msg.includes('limit')) {
        await wait(initialDelay * Math.pow(2, i));
        continue;
      }
      if (i < retries - 1) {
        await wait(initialDelay);
        continue;
      }
      throw error;
    }
  }
  throw lastError;
};

const STYLE_DIRECTIVES: Record<string, string> = {
  'Cinematic': 'Master-level cinematography, 35mm anamorphic lens, deep chiaroscuro shadows, Rembrandt lighting, volumetric haze, floating dust motes, 8k raw texture detail, shallow depth of field (f/1.8), cinematic color grading (teal and orange hints), epic scale, immersive atmosphere.',
  'Anime': 'Makoto Shinkai style, vibrant cel-shaded, expressive line art, stylized sky with fluffy clouds, saturated colors, hand-drawn aesthetic, high-quality modern anime.',
  'Cyberpunk': 'Neon noir, rainy streets with neon reflections, high contrast, volumetric fog, chromatic aberration, futuristic night city, aggressive teal and orange palette.',
  'Horror': 'Chiaroscuro lighting, heavy film grain, desaturated colors, eerie atmosphere, shadow play, unsettling micro-details, low-key lighting, suspenseful cinematic mood.',
  'Documentary': 'Naturalistic lighting, macro photography, realistic organic textures, neutral color palette, clean framing, high-fidelity details, authentic material realism.',
  'Unreal': 'Rendered in Unreal Engine 5, Nanite geometry, Lumen global illumination, 8K resolution, hyper-realistic 3D graphics, ray tracing, high fidelity, detailed textures, cinematic lighting, photorealistic game asset style.'
};

const augmentPromptWithStyle = (prompt: string, style: string) => {
  const directive = STYLE_DIRECTIVES[style] || STYLE_DIRECTIVES['Cinematic'];
  return `${prompt}. Technical Artistic Direction: ${directive}`;
};

const safeParseJson = (text: string) => {
  try {
    let cleanText = text.trim();
    if (cleanText.includes('```')) {
      cleanText = cleanText.replace(/```json/g, '').replace(/```/g, '').trim();
    }
    return JSON.parse(cleanText);
  } catch (e) {
    try {
      const start = text.indexOf('{');
      const end = text.lastIndexOf('}');
      if (start !== -1 && end !== -1) {
        return JSON.parse(text.substring(start, end + 1));
      }
    } catch (e2) { }
    throw new Error("AI generated invalid JSON. Please try again.");
  }
};

/**
 * Universal Script Generator
 */
export const generateScript = async (
  topic: string,
  mode: GeneratorMode,
  aspectRatio: '9:16' | '16:9',
  languageOverride?: 'Thai' | 'English',
  durationMinutes: number = 1,
  visualModel?: string,
  style: string = 'Cinematic',
  textModel: string = 'gemini-2.0-flash'
): Promise<ScriptData> => {
  if (mode === GeneratorMode.LONG_VIDEO) {
    return generateLongVideoScript(topic, '16:9', languageOverride, durationMinutes, style, textModel);
  }
  return generateShortsScript(topic, mode, aspectRatio, languageOverride, style, textModel);
};

/**
 * Specialized Script Generator for Shorts (Concise & Viral)
 */
export const generateShortsScript = async (
  topic: string,
  mode: GeneratorMode,
  aspectRatio: '9:16' | '16:9',
  languageOverride?: 'Thai' | 'English',
  style: string = 'Cinematic',
  textModel: string = 'gemini-2.0-flash'
): Promise<ScriptData> => {
  return withRetry(async () => {
    const ai = getClient();
    const styleDirectives = STYLE_DIRECTIVES[style] || STYLE_DIRECTIVES['Cinematic'];

    // STRICT: Detect language from topic to ensure mirroring‡∏à‡∏∞
    const detectedLang = detectLanguage(topic);
    const targetLang = (detectedLang === 'English') ? 'English' : (languageOverride || 'Thai');

    const systemInstruction = `You are a Professional Viral Content Creator & SEO Expert.
    STRICT LANGUAGE POLICY:
    - YOU MUST MIRROR THE LANGUAGE OF THE TOPIC.
    - TOPIC: "${topic}"
    - If the topic is in ENGLISH, the 'voiceover', 'title', and 'description' MUST be in ENGLISH.
    - If the topic is in THAI, the 'voiceover', 'title', and 'description' MUST be in THAI.
    - NEVER mix languages. If the user input is English, do not respond in Thai.
    - The ONLY field that MUST remain in English is 'visual_prompt'.

    CONTENT STYLE: ${style}.
    VISUAL DNA: ${styleDirectives}.

    PRODUCTION RULES:
    1. Hook the audience in the first 3 seconds.
    2. EXACTLY 5 SCENES.
    3. MAX 15 words per scene voiceover for fast-paced viral retention.
    
    SEO RULES (CRITICAL):
    - GENERATE A MASSIVE TAG CLOUD.
    - Title must be CLICKBAIT but relevant.
    - Long Description must include keywords naturally.`;

    const response = await ai.models.generateContent({
      model: textModel as any,
      contents: `Generate a script in ${targetLang} about: "${topic}".
      IMPORTANT:
      - Hashtags: Generate 50-100 viral hashtags.
      - Keywords: Generate a massive list of 100+ comma-separated SEO keywords.`,
      config: {
        systemInstruction,
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            title: { type: Type.STRING },
            seoTitle: { type: Type.STRING },
            description: { type: Type.STRING },
            longDescription: { type: Type.STRING, description: "A detailed, SEO-optimized description (3 paragraphs) packed with keywords." },
            seoKeywords: { type: Type.STRING, description: "A massive list of 100-200 comma-separated high-traffic keywords for metadata." },
            hashtags: { type: Type.ARRAY, items: { type: Type.STRING }, description: "Array of 60-100 viral hashtags." },
            scenes: {
              type: Type.ARRAY,
              minItems: 5, maxItems: 5,
              items: {
                type: Type.OBJECT,
                properties: {
                  id: { type: Type.INTEGER },
                  visual_prompt: { type: Type.STRING },
                  voiceover: { type: Type.STRING },
                  duration_est: { type: Type.NUMBER }
                },
                required: ["id", "visual_prompt", "voiceover", "duration_est"]
              }
            }
          },
          required: ["title", "seoTitle", "scenes", "longDescription", "seoKeywords", "hashtags"]
        }
      }
    });

    const data = safeParseJson(response.text || '{}');

    if (!data.longDescription) data.longDescription = data.description;

    return { ...data, scenes: (data.scenes || []).map((s: any) => ({ ...s, status: 'pending' })) };
  });
};

/**
 * Specialized Script Generator for Long Video (In-depth & Educational)
 */
export const generateLongVideoScript = async (
  topic: string,
  aspectRatio: '16:9',
  languageOverride?: 'Thai' | 'English',
  durationMinutes: number = 10,
  style: string = 'Cinematic',
  textModel: string = 'gemini-3-pro-preview'
): Promise<ScriptData> => {
  return withRetry(async () => {
    const ai = getClient();
    const styleDirectives = STYLE_DIRECTIVES[style] || STYLE_DIRECTIVES['Cinematic'];

    const targetWordCount = durationMinutes * 140;

    const detectedLang = detectLanguage(topic);
    const targetLang = (detectedLang === 'English') ? 'English' : (languageOverride || 'Thai');

    const systemInstruction = `You are a World-Class Documentary Filmmaker and Subject Matter Expert.
    STRICT LANGUAGE POLICY: Target Language: ${targetLang}.
    
    SEO INSTRUCTIONS:
    - Generate VERY LONG, detailed descriptions.
    - Include a massive list of keywords.`;

    const response = await ai.models.generateContent({
      model: textModel as any,
      contents: `Generate a highly detailed, educational documentary script about: "${topic}".
      Duration: ${durationMinutes} Minutes.
      Target Word Count: ${targetWordCount} words.`,
      config: {
        systemInstruction,
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            title: { type: Type.STRING },
            seoTitle: { type: Type.STRING },
            longDescription: { type: Type.STRING },
            seoKeywords: { type: Type.STRING, description: "Massive list of 200+ keywords." },
            hashtags: { type: Type.ARRAY, items: { type: Type.STRING } },
            scenes: {
              type: Type.ARRAY,
              minItems: 10,
              maxItems: 40,
              items: {
                type: Type.OBJECT,
                properties: {
                  id: { type: Type.INTEGER },
                  visual_prompt: { type: Type.STRING },
                  voiceover: { type: Type.STRING },
                  duration_est: { type: Type.NUMBER }
                },
                required: ["id", "visual_prompt", "voiceover", "duration_est"]
              }
            }
          },
          required: ["title", "seoTitle", "scenes"]
        }
      }
    });

    const data = safeParseJson(response.text || '{}');
    return { ...data, scenes: (data.scenes || []).map((s: any) => ({ ...s, status: 'pending' })) };
  });
};

export const refineVisualPrompt = async (topic: string, style: string, voiceover: string): Promise<string> => {
  return withRetry(async () => {
    const ai = getClient();
    const styleDirectives = STYLE_DIRECTIVES[style] || STYLE_DIRECTIVES['Cinematic'];
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `You are a Director of Photography. Enhance this scene concept into a professional 8K cinematic visual prompt in English.
      Scene Context: ${voiceover}
      Base Topic: ${topic}
      Technical Directives: ${styleDirectives}
      OUTPUT: One dense English paragraph describing lighting physics, camera lens (e.g. 35mm), specific angles, and atmospheric elements.`,
    });
    return response.text || "";
  });
};

export const generateStoryboards = async (topic: string, style: string, scenes: { id: number, voiceover: string }[]): Promise<Record<number, string>> => {
  return withRetry(async () => {
    const ai = getClient();
    const styleDirectives = STYLE_DIRECTIVES[style] || STYLE_DIRECTIVES['Cinematic'];
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `Generate visually consistent English storyboard prompts for this narrative sequence.
      Topic: ${topic}
      Visual DNA: ${styleDirectives}
      Timeline:
      ${scenes.map(s => `ID ${s.id}: ${s.voiceover}`).join('\n')}
      Return ONLY valid JSON: {"storyboards": [{"id": number, "prompt": string}]}`,
      config: { responseMimeType: "application/json" }
    });
    const data = safeParseJson(response.text || '{}');
    const result: Record<number, string> = {};
    (data.storyboards || []).forEach((item: any) => {
      result[item.id] = item.prompt;
    });
    return result;
  });
};

// üî• [‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á SEO Metadata ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ï‡πá‡∏° 500+ Keywords
export const generateSeoMetadata = async (topic: string, title: string, description: string): Promise<{ hashtags: string[], seoKeywords: string }> => {
  return withRetry(async () => {
    const ai = getClient();
    const lang = detectLanguage(topic);

    // Fix: Using gemini-3-pro-preview for complex text generation tasks
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: `You are a YouTube SEO God. 
      Generate a MASSIVE, EXTREME list of metadata in ${lang} for: "${topic}"
      Context Title: "${title}"
      
      REQUIREMENTS:
      1. hashtags: Generate exactly 100 high-volume viral hashtags. Mix broad (e.g. #fyp) and specific niche tags.
      2. seoKeywords: Generate 500+ (FIVE HUNDRED PLUS) comma-separated semantic keywords for the video tags section.
         - Include long-tail keywords.
         - Include misspellings.
         - Include related questions.
         - Include competitor tags.
         - MAKE IT MASSIVE.
      
      Output JSON only.`,
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            hashtags: { type: Type.ARRAY, items: { type: Type.STRING } },
            seoKeywords: { type: Type.STRING }
          }
        }
      }
    });
    return safeParseJson(response.text || '{}');
  });
};

export const generateVoiceover = async (text: string, voiceName: string): Promise<string> => {
  return withRetry(async () => {
    const ai = getClient();
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{
        parts: [{
          text: `Please read the following text with a ${voiceName} voice tone. Text: "${text}"`
        }]
      }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName } } },
      },
    });
    return response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data || "";
  });
};



export const generateVideoForScene = async (
  prompt: string,
  aspectRatio: '16:9' | '9:16',
  model: string = 'veo-3.1-fast-generate-preview',
  style: string = 'Cinematic',
  onProgress?: (pollingCount: number) => void
): Promise<string> => {
  return withRetry(async () => {
    const ai = getClient();
    const augmentedPrompt = augmentPromptWithStyle(prompt, style);
    const operation = await ai.models.generateVideos({
      model: model as any,
      prompt: augmentedPrompt,
      config: { numberOfVideos: 1, resolution: '720p', aspectRatio }
    });
    let op = operation;
    let pollCount = 0;
    while (!op.done) {
      pollCount++;
      onProgress?.(pollCount);
      await wait(8000);
      op = await ai.operations.getVideosOperation({ operation: op });
    }
    return `${op.response?.generatedVideos?.[0]?.video?.uri}&key=${process.env.API_KEY}`;
  });
};

export const generateImageForScene = async (prompt: string, model: string = 'gemini-2.0-flash-exp', aspectRatio: string = '9:16', style: string = 'Cinematic'): Promise<string | null> => {
  try {
    return await withRetry(async () => {
      const ai = getClient();
      const augmentedPrompt = augmentPromptWithStyle(prompt, style);

      // Add aspect ratio hint to prompt
      const aspectHint = aspectRatio === '9:16' ? 'vertical portrait format' : 'horizontal landscape format';
      const finalPrompt = `${augmentedPrompt}. Generate in ${aspectHint}.`;

      // Use Gemini native image generation via generateContent
      const response = await ai.models.generateContent({
        model: 'gemini-2.0-flash-exp',
        contents: [{ parts: [{ text: finalPrompt }] }],
        config: {
          responseModalities: [Modality.IMAGE, Modality.TEXT],
        }
      });

      // Extract image from response
      const parts = response.candidates?.[0]?.content?.parts || [];
      for (const part of parts) {
        if (part.inlineData?.mimeType?.startsWith('image/')) {
          return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
        }
      }

      throw new Error("No image data in response");
    });
  } catch (err: any) {
    console.error("Image Gen failed:", err.message);
    return null;
  }
};

// Simple in-memory cache
const newsCache: Record<string, { timestamp: number, data: NewsItem[] }> = {};
const CACHE_TTL = 5 * 60 * 1000;

export const fetchTrendingNews = async (region: string, category: string, searchQuery: string = ''): Promise<NewsItem[]> => {
  const cacheKey = `${region}-${category}-${searchQuery}`;
  const now = Date.now();
  if (newsCache[cacheKey] && (now - newsCache[cacheKey].timestamp < CACHE_TTL)) {
    console.log('Using cached news for:', cacheKey);
    return newsCache[cacheKey].data;
  }

  return withRetry(async () => {
    const ai = getClient();
    const lang = region === 'thailand' ? 'Thai' : 'English';
    const response = await ai.models.generateContent({
      model: "gemini-3-flash-preview",
      contents: `Search for 6 viral news stories in ${region}. Category: ${category}. Query: ${searchQuery}. Language: ${lang}.`,
      config: {
        tools: [{ googleSearch: {} }],
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.ARRAY,
          items: {
            type: Type.OBJECT,
            properties: {
              headline: { type: Type.STRING },
              summary: { type: Type.STRING },
              category: { type: Type.STRING },
              virality_score: { type: Type.NUMBER },
              velocity: { type: Type.STRING },
              est_reach: { type: Type.STRING },
              source: { type: Type.STRING }
            },
            required: ["headline", "summary", "category"]
          }
        }
      }
    });

    const news = safeParseJson(response.text || '[]');
    const results = news.map((item: any, idx: number) => ({
      ...item,
      id: `news-${idx}-${Date.now()}`
    }));
    newsCache[cacheKey] = { timestamp: Date.now(), data: results };
    return results;
  });
};

export const generateThumbnail = async (title: string, topic: string, style: string = 'Cinematic'): Promise<string> => {
  return generateImageForScene(`Viral high-impact YouTube thumbnail. Topic: ${topic}. Hook: ${title}. High-contrast, clickable graphic design.`, 'gemini-2.5-flash-image', '16:9', style);
};

export const generatePodcastAudio = async (text: string, voiceA: string, voiceB: string): Promise<string> => {
  return withRetry(async () => {
    const ai = getClient();
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{ parts: [{ text }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          multiSpeakerVoiceConfig: {
            speakerVoiceConfigs: [
              { speaker: 'Speaker 1', voiceConfig: { prebuiltVoiceConfig: { voiceName: voiceA } } },
              { speaker: 'Speaker 2', voiceConfig: { prebuiltVoiceConfig: { voiceName: voiceB } } }
            ]
          }
        }
      }
    });
    return response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data || "";
  });
};

export const summarizeScript = async (script: ScriptData): Promise<string[]> => {
  return withRetry(async () => {
    const ai = getClient();
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `Summarize this script into clear, engaging bullet points. JSON format {bullets:[]}. Script context: ${script.scenes.map(s => s.voiceover).join("\n")}`,
      config: { responseMimeType: "application/json" }
    });
    return safeParseJson(response.text || '{}').bullets || [];
  });
};

export const generateSocialPost = async (topic: string, platform: string, lang: string): Promise<SocialPostData> => {
  return withRetry(async () => {
    const ai = getClient();
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `Generate a high-engagement ${platform} post for ${topic} in ${lang}. Format: JSON {caption:"", hashtags:[], image_prompt:""}`,
      config: { responseMimeType: "application/json" }
    });
    return safeParseJson(response.text || '{}');
  });
};

// --- AI Integration Flow: Image to Video Pipeline ---

/**
 * Generate video from image URL using backend pipeline.
 * - useMotion=true: Uses Replicate AI (Stable Video Diffusion) - COSTS MONEY
 * - useMotion=false: Uses FFmpeg Ken Burns effect - FREE
 * 
 * @param imageUrl - URL of the source image (must be publicly accessible)
 * @param useMotion - true for AI motion, false for static Ken Burns
 * @param aspectRatio - '9:16' for Shorts, '16:9' for landscape
 * @param onProgress - Optional callback for polling progress
 * @returns Promise<string> - URL of the generated video
 */
export const generateVideoFromImage = async (
  imageUrl: string,
  useMotion: boolean = false,
  aspectRatio: '9:16' | '16:9' = '9:16',
  audioUrl?: string, // NEW: Optional audio URL
  onProgress?: (status: string, pollCount: number) => void,
  onJobCreated?: (jobId: string) => void // NEW: Callback to save Job ID
): Promise<string> => {
  try {
    // Step 1: Start video generation job
    const startRes = await fetch('/api/generate-video', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ imageUrl, useMotion, aspectRatio, audioUrl }) // Pass audioUrl
    });

    const startData = await startRes.json();

    if (startData.error) {
      throw new Error(startData.error);
    }

    // If Static mode (FFmpeg), response is immediate
    if (startData.mode === 'static' && startData.status === 'succeeded') {
      return startData.output[0];
    }

    // Step 2: Poll for completion (Motion mode via Replicate)
    if (!startData.jobId) {
      throw new Error('No jobId returned from server');
    }

    // Notify caller of Job ID for persistence
    onJobCreated?.(startData.jobId);

    return pollVideoStatus(startData.jobId, onProgress);

  } catch (error: any) {
    console.error('generateVideoFromImage error:', error);
    throw error;
  }
};

/**
 * Polls the backend for video job status until completion.
 * Can be used to resume monitoring disconnected jobs.
 */
export const pollVideoStatus = async (
  jobId: string,
  onProgress?: (status: string, pollCount: number) => void
): Promise<string> => {
  return new Promise((resolve, reject) => {
    let pollCount = 0;
    const maxPolls = 600; // 10 minutes timeout extended for queue

    const pollInterval = setInterval(async () => {
      try {
        pollCount++;
        onProgress?.('generating', pollCount);

        const statusRes = await fetch(`/api/check-status/${jobId}`);
        const statusData = await statusRes.json();

        if (statusData.status === 'succeeded') {
          clearInterval(pollInterval);
          const videoUrl = Array.isArray(statusData.output)
            ? statusData.output[0]
            : statusData.output;
          resolve(videoUrl);
        } else if (statusData.status === 'failed') {
          clearInterval(pollInterval);
          reject(new Error(statusData.error || 'Video generation failed'));
        } else if (pollCount >= maxPolls) {
          clearInterval(pollInterval);
          reject(new Error('Video generation timed out'));
        }
        // else continue polling
      } catch (pollError: any) {
        clearInterval(pollInterval);
        reject(new Error('Polling error: ' + pollError.message));
      }
    }, 2000); // Poll every 2 seconds
  });
};

/**
 * Mix video with audio using backend FFmpeg endpoint.
 * Output is 720p (Render Free Tier limit) and uploaded to Supabase.
 * 
 * @param videoUrl - URL of the source video
 * @param audioUrl - URL of the audio track
 * @param aspectRatio - '9:16' for Shorts, '16:9' for landscape
 * @returns Promise<string> - URL of the final mixed video
 */
export const renderFinalVideo = async (
  videoUrl: string,
  audioUrl: string,
  aspectRatio: '9:16' | '16:9' = '9:16'
): Promise<string> => {
  try {
    const res = await fetch('/api/render-final', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ videoUrl, audioUrl, aspectRatio })
    });

    const data = await res.json();

    if (data.error) {
      throw new Error(data.error);
    }

    return data.url;

  } catch (error: any) {
    console.error('renderFinalVideo error:', error);
    throw error;
  }
};